# 36_数据增广QA

## 问题1:理论上，是不是如果原始样本如果足够多，就用不着做增广？

答：一种理想情况是，训练样本比较多覆盖到了测试样本，这样是OK的。但现实往往不是，举个栗子，智能音响，原始样本对实际的覆盖往往是不够的。

## 问题2:老师， num worker的值是不是根据机器GPU性能而设定？

答：一般是开一个Epoch，多尝试直到性能提升不明显甚至下降就可以不增加num_worker。一般4就不错了

## 题3:老师，金融风控领域经常碰到的数据都是极度偏斜数据（欺诈样本/正样本比例只占1%),是否可以针对正样本试试类似今天讲的数据增强(之前使用重采样，效果一般般)？

答：通常需要重采样，增广

## 问题4:老师，测试一般做什么样的增广？测试增广在比赛中能提高精度如何理解？

答：测试一般不做增广。在比赛中，将一个样本，多resize或者randomcrop等操作去预测做平均。但在实际应用中做的不多，因为对机器要求变高。

## 问题5:老师，课件里提到的对比试验固定了所有随机种子吗？做完增广之后，训练精度下降，是不是意味着还可以继续训练，减少gap?

答：这里没有设置随机种子。cifar10的没有完全收敛。gap后面只会增加，不会减少，可能训练精度会上升。

## 问题6:请问老师图片增加广后需要人工一张张确认是否有效吗？

答：可以看看效果。

## 问题7:老师，做了图片增后，训练数据的分布可能会和测试数据的分布不一样，那会对模型最终精度有影响吗？

答:均值还是不变的。分布还是不发生变化的。多样性增加了。

## 问题8:老师您好，后面会讲图神经网络吗？听说图神经网络挺强大的，老师可以稍微讲解一下吗？

答：是很强大，不好收敛，性能很慢。应用上现在不成熟

## 问题9:老师，怎么理解 mosaic这种增广方式？把不同图片crop之后拼接在起， label也是拼接的。为什么有效呢？

答：mosaic是4张图拼起来，这里老师貌似讲错了。

## 问题10:老师好，最后对比没增广的训练精度和测试精度时，训练集用的是测试集，那最后同时把这这些作为训练集的测试集当做测试集时，为什么测试精度不是100%呢？

答： 这里是在训练集上使用测试集的增广方式。而不是代表测试集

## 问题11:使用对一个事物的视频描述做数据集，是不是效果会更有效，对比于比这样的增广？

答：视频更好，成本更高

## 问题12:多张图片疊加，是不是也是一种有效的增广方式？

答：MixUP

## 问题13:老师，做车辆位置识别，如果实际应用场景摄像头高度和角度清晰度都和训练集不一样，是不是只能针对场景单独采集数据重新打标训练

答：一开始可以使用非场景的模型就行部署，一段时间后，查看当前场景中哪些方面没做好，再重新加入模型进行训练。主动学习，分类对的图片不用管了，分类错的图片重新标一下，加入训练集重新训练下。

## 问题14:图像增广的样本会不会跟原始样本有混淆结果，比如样本A做图像增广后A跟B样本相似度从80%升到了90%

答：增广目的为了使训练集长得像测试集。

## 问题15:如何理解多样性增加，但是分布不变？

答“增广，使方差不同，均值相同。单一类别数量过多

## 问题16:miⅸ-up増广为什么有效呢？测试集中不会出现这样的样本？

答：类似鬼影效果。

## 问题18:老师，想问下，想做一个加油锥套的识别，并且测量实际距离。用yolo做识别后，有什么办法能提高測量距离的精度？以及做数据集的时候有什么要注意的重点吗？

感觉这个是不是空中飞机加油

## 问题19:请问老师实际操作时使用 torchvision?好呢还是 albumentation好？

答：图片识别很成熟了，没区别