# 35_分布式训练QA

## 问题27: pytorch怎么设置不同gpu不同的 batch size呢？比如刚才提到的两种不同的gpu放在一起训练的情况

答：device load参数设置，在DataParallel中有个参数设置。

## 问题28:分布式的目的也是和 data parallel--样提升计算速度吗？为什么不能只用 data parallel就解決这个问题呢，是因为分布式多了一些通信的技术吗？

答：我们这里讨论的是data parallel怎么应用在单机多卡和分布式上。本质上是一个东西

## 问题29:每个参数服务器求完梯度之后，还要汇总到一个主服务器，然后再分发给各个参数服务器，然后再传给计算节点吗？

答：不是的，最简单是就一台服务器，我这里汇总。假设有三台，三台上都有模型参数，每个worker要模型时向三台机器请求各自模型然后在本地汇总。

## 问题30:每个GPU都得到了模型的所有的参数吗？

答：在数据并行中是的。

## 问题31:为什么n个GPU会相对于单个GPU加速n倍？我的理解是，一batch假设有m个样本，在单个GPU中其实也是并行跑的。所以按照这样的说法，用n个GPU其实并行度没有增大，所以时间是不是应该是一样的？

答：之前1gpu处理100样本/秒，现在10个gpu处理1000样本/秒；

## 问题34:请问老师，在分布式集群进下训练时，为什么计算和数据通讯可以并行？单机上不是要等梯度算完，传到参数服务器上，等所有梯度集合更新后，才能拿到下一个新的模型参数吗

答：计算通讯不是完美并行的。

## 问题35:老师，分布式多个9gpu相当于增大 batch size,一般情况下， batchsize超过2048是不是就不好了啊？那为什么要用分布式，是为了训练大模型？ batch size可以加到几千几万吧？

答：取决于数据集，类别数，和算法。n个类，bs = 10 * n